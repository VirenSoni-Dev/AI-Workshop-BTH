{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOY/5ajDI98JhbaxGmWsYmQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alphakhush2201/AI-Workshop-BTH/blob/main/Untitled14.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Introduction to AI coding assistant\n",
        "AI Coding assistants are tools powered by ML Models (Often uses LLMs) that helps\n",
        "developer to write, fix or understand the code.\n",
        "They assist with code generation, debugging, documentation and many more.\n",
        "\n",
        "Benefits:\n",
        "1. Speed(accelerate development with code suggestion)\n",
        "2. Productivity(Reduces Time spent switching context)\n",
        "3. Accessbility(Assist beginner by explaining code)\n",
        "\n",
        "\n",
        "Limitations:\n",
        "1. May Suggest Incorrect code\n",
        "2. Limited Understanding of full project context\n",
        "3. Risk of Overdependence for beginners(Vibe Coders)\n",
        "\n",
        "Example of Platforms:\n",
        "1. Github Copilot(suggest realtime in vs code using OpenAI Codex)\n",
        "2. Gemini Code Assistant(Google AI Assistant for code integrated with workspace and google cloud)\n",
        "3. Amazon Code Whisper(AWS Native Assistant for writing Cloud related code)\n",
        "4. Cursor(AI first code Editor with powerful\n",
        "auto complete, Inline Chat and agent workflows)\n",
        "5. Tabnine(Privacy focused AI code tool teams)\n",
        "\n",
        "\n",
        "Demonstration and Case Studies:\n",
        "Use Cases:\n",
        "1. Code Generation(Auto generated functions and classes)\n",
        "2. Code Completion(predict the next line of code)\n",
        "3. Debugging(Suggest bug fixes)\n",
        "4. Auditing(Identify Security Issues)\n",
        "5. Documentation(Generate Doc Strings and Readmes)\n",
        "6. Agentic Workflows(MultiStep AI Agent that can perform Complex Development task like finding a bug and fixing it, writing a test and pushing it to a repo automatically)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "UNASavY_kXqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gradio torchvision torch pillow #gradio: Build GUI for ML Models/Apps,\n",
        "# torch: Pytorch Deep learning networks , torchvision: Pretrained Image model like resnet\n",
        "# pillow: image Handling\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxdK1gy3kcjm",
        "outputId": "13364e64-d2f1-4463-8bb4-42067d9fbc95"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import required LIBs\n",
        "\n",
        "import gradio as gr\n",
        "from torchvision import models, transforms\n",
        "from torchvision.models import ResNet50_Weights\n",
        "from PIL import Image\n",
        "import torch\n",
        "import urllib.request\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_EHC2yxqo_Uy"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Load pretrained resnet 50 and set to eval mode\n",
        "model = models.resnet50(weights=ResNet50_Weights.DEFAULT)\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "bRn0y8PWptZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load Imagenet class labels\n",
        "LABELS_URL = \"https://raw.githubusercontent.com/pytorch/hub/master/imagenet_classes.txt\"\n",
        "imagenet_classes = urllib.request.urlopen(LABELS_URL).read().decode(\"UTF-8\").splitlines()"
      ],
      "metadata": {
        "id": "5u1sAbg9q7Ru"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 5: Define Image Preprocessing pipeline\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "])"
      ],
      "metadata": {
        "id": "Tj6YY9LMsnQT"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6: Define Prediction Functions\n",
        "def predict(img):\n",
        "  if not isinstance(img,Image.Image):\n",
        "    img = Image.fromarray(img)\n",
        "  img = preprocess(img).unsqueeze(0)\n",
        "  with torch.no_grad():\n",
        "    outputs = model(img)\n",
        "  _, index = outputs[0].max(0)\n",
        "  label = imagenet_classes[index.item()]\n",
        "  return f\"Predicted: {label} (class index:{index.item()})\"\n"
      ],
      "metadata": {
        "id": "RKE3ZreptJUK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Launch Gradio App(GUI)\n",
        "\n",
        "gr.Interface(fn=predict, inputs=gr.Image(type=\"pil\"), outputs= \"text\",\n",
        "             title= \"AI Object Classifier(Imagenet)\").launch(share=True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "4GupUvpzum9I",
        "outputId": "bf692b2e-2280-4db8-b847-094026c08906"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://393b614a6cc7873b2d.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://393b614a6cc7873b2d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}